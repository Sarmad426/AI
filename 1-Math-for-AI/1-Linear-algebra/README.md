# Linear Algebra

Linear algebra is central to data representation, transformations, and high-dimensional spaces in ML and DL. Concepts include:

- **Vectors and Matrices**: Understanding how to manipulate these is essential for handling data in high-dimensional spaces.
- **Matrix Operations**: Matrix addition, multiplication, and inverses are foundational for many ML algorithms, including support vector machines (SVMs) and neural networks.
- **Eigenvalues and Eigenvectors**: These concepts are crucial in Principal Component Analysis (PCA) for dimensionality reduction and in understanding how transformations work.

**Uni variants:**

Analysis of a single variable

**Example:** Calculating the mean of a dataset (GPA of students)

**Multi variants:**

Analysis of multiple variables.

**Example:** Predicting the price of a house based on its size, location, etc.

## Data Types

- **Scalar**: A single number. 0-D (dimensional).
- **Vector**: An array of numbers. 1-D.
- **Matrix**: A 2-D array of numbers. 2-D.
- **Tensor**: An n-dimensional array of numbers. 3-D or higher.

**3D tensors:** used for time series data or sequence data.

**4D tensors:** used for image data.

**5D tensors:** used for video data.
